{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a simple neural-network with Keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q modelify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (10,10) # Make the figures a bit bigger\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets.mnist import load_data\n",
    "\n",
    "# load the data - it returns 2 tuples of digits & labels - one for\n",
    "# the train set & the other for the test set\n",
    "(train_digits, train_labels), (test_digits, test_labels) = load_data()\n",
    "\n",
    "# display 14 random images from the training set\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "\n",
    "rand_14 = np.random.randint(0, train_digits.shape[0],14)\n",
    "sample_digits = train_digits[rand_14]\n",
    "sample_labels = train_labels[rand_14]\n",
    "# code to view the images\n",
    "num_rows, num_cols = 2, 7\n",
    "f, ax = plt.subplots(num_rows, num_cols, figsize=(12,5),\n",
    "                     gridspec_kw={'wspace':0.03, 'hspace':0.01}, \n",
    "                     squeeze=True)\n",
    "\n",
    "for r in range(num_rows):\n",
    "    for c in range(num_cols):\n",
    "        image_index = r * 7 + c\n",
    "        ax[r,c].axis(\"off\")\n",
    "        ax[r,c].imshow(sample_digits[image_index], cmap='gray')\n",
    "        ax[r,c].set_title('No. %d' % sample_labels[image_index])\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some variables...\n",
    "image_height = train_digits.shape[1]  \n",
    "image_width = train_digits.shape[2]\n",
    "num_channels = 1  # we have grayscale images\n",
    "# NOTE: image_height == image_width == 28\n",
    "\n",
    "# re-shape the images data\n",
    "train_data = np.reshape(train_digits, (train_digits.shape[0], image_height, image_width, num_channels))\n",
    "test_data = np.reshape(test_digits, (test_digits.shape[0],image_height, image_width, num_channels))\n",
    "\n",
    "# re-scale the image data to values between (0.0,1.0]\n",
    "train_data = train_data.astype('float32') / 255.\n",
    "test_data = test_data.astype('float32') / 255.\n",
    "\n",
    "# one-hot encode the labels - we have 10 output classes\n",
    "# so 3 -> [0 0 0 1 0 0 0 0 0 0], 5 -> [0 0 0 0 0 1 0 0 0 0] & so on\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "num_classes = 10\n",
    "train_labels_cat = to_categorical(train_labels,num_classes)\n",
    "test_labels_cat = to_categorical(test_labels,num_classes)\n",
    "train_labels_cat.shape, test_labels_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the training dataset (5 times!)\n",
    "for _ in range(5): \n",
    "    indexes = np.random.permutation(len(train_data))\n",
    "\n",
    "train_data = train_data[indexes]\n",
    "train_labels_cat = train_labels_cat[indexes]\n",
    "\n",
    "# now set-aside 10% of the train_data/labels as the\n",
    "# cross-validation sets\n",
    "val_perc = 0.10\n",
    "val_count = int(val_perc * len(train_data))\n",
    "\n",
    "# first pick validation set from train_data/labels\n",
    "val_data = train_data[:val_count,:]\n",
    "val_labels_cat = train_labels_cat[:val_count,:]\n",
    "\n",
    "# leave rest in training set\n",
    "train_data2 = train_data[val_count:,:]\n",
    "train_labels_cat2 = train_labels_cat[val_count:,:]\n",
    "\n",
    "# NOTE: We will train on train_data2/train_labels_cat2 and \n",
    "# cross-validate on val_data/val_labels_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    # add Convolutional layers\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same',\n",
    "                     input_shape=(image_height, image_width, num_channels)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))    \n",
    "    model.add(Flatten())\n",
    "    # Densely connected layers\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    # output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # compile with adam optimizer & categorical_crossentropy loss function\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit(train_data2, train_labels_cat2, \n",
    "                    epochs=1, batch_size=64,\n",
    "                    validation_data=(val_data, val_labels_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = \\\n",
    "  model.evaluate(test_data, test_labels_cat, batch_size=64)\n",
    "print('Test loss: %.4f accuracy: %.4f' % (test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data)\n",
    "first20_preds = np.argmax(predictions, axis=1)[:9]\n",
    "first20_true = np.argmax(test_labels_cat,axis=1)[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i, correct in enumerate(first20_preds):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(test_data[i][:,:, 0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(first20_preds[i], first20_true[i]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modelify\n",
    "from modelify import ModelInference\n",
    "from modelify.inputs import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_input = Image(width=28, height=28, channel=1) # images are grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_input.add_sample(\"https://machinelearningmastery.com/wp-content/uploads/2019/02/sample_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = ModelInference(model=model, framework=\"KERAS\", inputs=my_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add postprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_postprocess(outputs):\n",
    "    import numpy as np\n",
    "    return np.argmax(outputs, axis=1).tolist() # take the highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference.postprocess = my_postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an API on local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelify.run(inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy to Modelify Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelify.connect(\"YOUR_CONNECTION_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelify.deploy(inference, app_uid=\"YOUR_APP_UID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
